# [A Large Scale Survey of Motivation in Software Development and Analysis of its Validity](https://arxiv.org/pdf/2404.08303)

**Context:** Motivation is known to improve performance. In software development in particular, there has been considerable interest in the
motivation of contributors to open-source.

**Objective:** We identify 11 motivators from the literature (enjoying programming, ownership of code, learning, self-use, etc.), and evaluate their relative
effect on motivation. Since motivation is an internal subjective feeling, we also
analyze the validity of the answers.

**Method:** We conducted a survey with 66 questions on motivation which was
completed by 521 developers. Most of the questions used an 11-point scale. We
evaluated the answers’ validity by comparing related questions, comparing to
actual behavior on GitHub, and comparison with the same developer in a
follow-up survey.

**Results:** Validity problems include moderate correlations between answers to
related questions, as well as self-promotion and mistakes in the answers. Despite these problems, predictive analysis—investigating how diverse motivators
influence the probability of high motivation—provided valuable insights. The
correlations between the different motivators are low, implying their independence. High values in all 11 motivators predict increased probability of high
motivation. In addition, improvement analysis shows that an increase in most
motivators predicts an increase in general motivation.

**Conclusions:** All 11 motivators indeed support motivation, but only moderately. No single motivator suffices to predict high motivation or motivation
improvement, and each motivator sheds light on a different aspect of motivation. Therefore models based on multiple motivators predict motivation
improvement with up to 94% accuracy, better than any single motivator.

**Keywords:** Motivation · Software engineering · Open-source development · Survey validity


# Repository content
This repository contains the data and source code used for this paper.
To reproduce see [code/python/main.py](https://github.com/evidencebp/motivation/blob/master/code/python/main.py)
Note that original [data](https://github.com/evidencebp/motivation/tree/master/data) contained personal identifiers (e.g., GitHub profiles), which was anonymized before publishing.

See also [additional analysis](https://github.com/evidencebp/motivation-survey/tree/main/additional%20analysis), not included in the paper due to length.
The analysis included demography and its comparison to the Stack Overflow annual survey.
It also contains the use of reduction to supervised learning to differ between participants contacted by email and by social media (they are rather similar).
Last, it contains an analysis between the different motivators.

[Code](https://github.com/evidencebp/motivation-survey/tree/main/code) contains the Python scripts and SQL queries needed for the research. [Emails](https://github.com/evidencebp/motivation-survey/tree/main/emails) contains the text that we sent.
[Figures](https://github.com/evidencebp/motivation-survey/tree/main/figures) includes the images from the paper, and more images demonstrating results and generated by the analysis code.
[Models](https://github.com/evidencebp/motivation-survey/tree/main/models) contain pkl file of sk-learn model and readable SQL representation of suitable models.
[Perfomance](https://github.com/evidencebp/motivation-survey/tree/main/performance) presents the predictive performance of various models.
In [stats](https://github.com/evidencebp/motivation-survey/tree/main/stats) the results of the analyzing code are stored.

